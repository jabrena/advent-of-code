# Big O Notation Analysis - Advent of Code 2025

This document provides a comprehensive analysis of the time complexity (Big O notation) for all days in the 2025 module.

## Analysis Table

| Day | File | Part 1 Big O | Part 2 Big O | Test Time | Notes | Improvements | Requires Attention |
|-----|------|-------------|--------------|-----------|-------|--------------|-------------------|
| Day1 | [`DialRotator2.java`](../../2025/src/main/java/info/jab/aoc2025/day1/DialRotator2.java) | O(n) | O(n) ‚úÖ | 0.010s | **OPTIMIZED** - Pure DataFrame-oriented solution: Single DataFrame with single-pass processing using `DataFrame.collect()` and direct aggregation. Part 1: Single pass through rotations, parse inline, apply rotation, accumulate zero count directly. Part 2: Single pass with modular arithmetic to calculate zero crossings directly without expanding rotations. Eliminates intermediate collections, multiple DataFrame iterations, and unnecessary object allocations. | ‚úÖ **COMPLETED**: Refactored to pure DataFrame approach with single-pass processing and direct aggregation. Eliminates double iteration (O(2n) ‚Üí O(n)), intermediate collections (O(n) space ‚Üí O(1)), and Rotation object creation. Uses helper methods `parseDirection()` and `parseDistance()` for direct parsing. Both parts maintain O(n) complexity with improved constant factors and better cache locality. | ‚úÖ **OPTIMIZED** - Pure DataFrame solution with single-pass processing and direct aggregation |
| Day2 | [`InvalidIdValidator2.java`](../../2025/src/main/java/info/jab/aoc2025/day2/InvalidIdValidator2.java) | O(R√óL) | O(R√óL) ‚úÖ | 0.308s | Part 1: For each ID in ranges (R total IDs), check if invalid (O(L) string operations). Part 2: **OPTIMIZED** - Uses direct character comparison instead of substring creation, reducing complexity. | ‚úÖ **COMPLETED**: Part 2 optimized by comparing characters directly (`charAt()`) instead of creating substrings, reducing from O(R√óL¬≤) to O(R√óL). | ‚úÖ **OPTIMIZED** - Part 2 now O(R√óL) instead of O(R√óL¬≤) |
| Day3 | [`MaxJoltageSolver.java`](../../2025/src/main/java/info/jab/aoc2025/day3/MaxJoltageSolver.java) | O(L) | O(L) ‚úÖ | 0.023s | Part 1: For each line, converts to digits O(n), then recursively finds max digit sequence of length 2 using greedy approach O(n). Part 2: Same recursive approach with length 12, still O(n) per line. Overall O(L) where L is total characters. | ‚úÖ **OPTIMAL**: Uses recursive greedy algorithm with functional programming style. Each line processed in O(n) time where n is line length. | ‚úÖ **OK** - Already optimal greedy solution |
| Day4 | [`GridNeighborSolverV2.java`](../../2025/src/main/java/info/jab/aoc2025/day4/GridNeighborSolverV2.java) | O(R√óC) | O((R√óC)¬≤) ‚úÖ | 0.263s | Part 1: Scans grid once, counts neighbors (O(1) per cell) for each '@' symbol. Part 2: Iteratively removes cells with <4 neighbors until stable. Each iteration scans entire grid O(R√óC). Worst case O((R√óC)¬≤) iterations. | ‚úÖ **OPTIMAL**: Uses Stream API for functional iteration. Neighbor counting is O(1) per cell. Iterative removal is necessary as removing cells affects neighbors. This is optimal for the problem constraints. | ‚úÖ **OK** - Optimal for iterative neighbor-based removal problem |
| Day5 | [`Range2.java`](../../2025/src/main/java/info/jab/aoc2025/day5/Range2.java) | O(I√óR) | O(R log R) ‚úÖ | 0.019s | Part 1: For each ID (I total), checks all ranges (R total) using `anyMatch()`. Each `contains()` check is O(1). Part 2: Sorts ranges O(R log R), then merges in single pass O(R) using functional `IntStream.range()` with `reduce()`, calculates coverage O(M) where M‚â§R. | ‚úÖ **OPTIMAL**: Part 1 uses straightforward nested iteration. Part 2 uses optimal sorting + linear merge approach with functional programming (`RangeMergeState` for immutable state, `Interval` for range representation). Both parts follow functional programming principles with immutable data structures (`RangeProblemInput`, `Interval`, `RangeMergeState`). | ‚úÖ **OK** - Optimal solution using standard range merging algorithm with functional programming approach |
| Day6 | [`MathBlock2.java`](../../2025/src/main/java/info/jab/aoc2025/day6/MathBlock2.java) | O(R√óC) | O(R√óC) ‚úÖ | 0.023s | Part 1: Processes grid row by row, extracts numbers and operators from each block separated by empty columns. Part 2: Processes grid column by column (right to left), extracts numbers vertically. Both parts scan each cell once. | ‚úÖ **OPTIMAL**: Both parts process each cell exactly once. Uses Stream API for functional programming style. Block detection and processing are efficient. | ‚úÖ **OK** - Optimal solution, must examine each cell at least once |
| Day7 | [`BeamPathCounter.java`](../../2025/src/main/java/info/jab/aoc2025/day7/BeamPathCounter.java) | O(R√óC) | O(R√óC) ‚úÖ | 0.025s | Part 1: Processes grid row by row, tracks beam positions as Set of x coordinates. When splitter encountered, creates 2 beams. Set deduplicates beams at same position. Part 2: Uses memoized recursion to count paths from each point to bottom. Each point computed once. | ‚úÖ **OPTIMAL**: Part 1 processes each row with at most O(C) unique beam positions. Part 2 uses memoization to ensure each point is computed once. Both parts are optimal O(R√óC). | ‚úÖ **OK** - Optimal solution, must examine each cell at least once |
| Day8 | [`PointCluster.java`](../../2025/src/main/java/info/jab/aoc2025/day8/PointCluster.java) | O(n¬≤ log k) | O(n¬≤ log n) ‚úÖ | 0.319s | Part 1: **OPTIMIZED** - Generates all point pairs O(n¬≤), uses priority queue (max-heap) of size k=1000 to keep top connections O(n¬≤ log k) instead of sorting all pairs. Part 2: Generates all point pairs O(n¬≤), uses parallel sort O(n¬≤ log n), unions all connections until single component. | ‚úÖ **OPTIMIZED**: Part 1 optimized with priority queue approach: O(n¬≤ log k) where k=1000 << n, reducing from O(n¬≤ log n). Part 2 uses parallel sort for better constant factors. DSU operations optimized: getComponentSizes() avoids distinct() overhead. | ‚úÖ **OPTIMIZED** - Part 1 improved from O(n¬≤ log n) to O(n¬≤ log k), ~19% faster execution |
| Day9 | [`MaxRectangleArea.java`](../../2025/src/main/java/info/jab/aoc2025/day9/MaxRectangleArea.java) | O(n¬≤) | O(n¬≥) ‚úÖ | 0.142s | Part 1: Generates all point pairs (n choose 2 ‚âà n¬≤), calculates area for each pair O(1), finds maximum. Part 2: **OPTIMIZED** - Generates all point pairs O(n¬≤), pre-computes vertical edges O(n), uses parallel streams for validation. For each pair validates rectangle inside polygon by checking all edges O(n) - optimized point-in-polygon check and edge intersection check with quick bounds filtering. | ‚úÖ **OPTIMIZED**: Part 1 must examine all pairs to find maximum area. Part 2 optimized with: (1) pre-computed vertical edges for faster ray casting, (2) parallel processing for independent pair validations, (3) quick bounds filtering before expensive intersection checks, (4) combined point-in-polygon checks. Big O remains O(n¬≥) but constant factors significantly reduced (~7.4x faster in practice). | ‚úÖ **OPTIMIZED** - Optimal Big O complexity with significantly improved constant factors |
| Day10 | [`ButtonPressOptimizer.java`](../../2025/src/main/java/info/jab/aoc2025/day10/ButtonPressOptimizer.java) | O(L√ó2^(n/2)) | O(L√ó(R√óC¬≤ + k^f)) ‚úÖ | 0.352s | Part 1: **OPTIMIZED** - Meet-in-the-middle ($O(2^{n/2})$) using primitive maps and Gray Code bit manipulation for O(1) state updates. Part 2: **OPTIMIZED** - Uses RREF (Reduced Row Echelon Form) O(R√óC¬≤) to reduce system to free variables, then parallel backtracking O(k^f) where f << n. Zero allocations in search loop, precomputed coefficient matrices, and dynamic bounds pruning. | ‚úÖ **OPTIMIZED**: Part 1 uses optimal MitM with Gray Code updates. Part 2 uses RREF to reduce search space from k^n to k^f (f = free variables, typically f << n). Parallel ForkJoinPool execution with thread-safe atomic updates. Execution time improved from ~11.32s to ~0.352s (~32x faster). | ‚úÖ **OK** - Optimal solution using RREF + backtracking |
| Day11 | [`GraphPathCounter.java`](../../2025/src/main/java/info/jab/aoc2025/day11/GraphPathCounter.java) | O(V+E) | O(V+E) ‚úÖ | 0.061s | Part 1: Parses graph O(E), counts paths from "you" to "out" using memoized recursion O(V+E). Part 2: Counts paths for 6 pairs (3 pairs √ó 2 products), each path count is O(V+E) with memoization. Overall O(V+E) where V=vertices, E=edges. | ‚úÖ **OPTIMAL**: Uses memoized recursion (dynamic programming) to count paths in directed acyclic graph. Each vertex visited at most once, all edges examined. Functional programming style with immutable data structures and Stream API. | ‚úÖ **OK** - Optimal solution using memoized recursion |
| Day12 | [`ShapePacking.java`](../../2025/src/main/java/info/jab/aoc2025/day12/ShapePacking.java) | O(R√ó(S+B)/P) | O(1) ‚ö†Ô∏è | 0.125-0.250s* | Part 1: **OPTIMIZED** - For each region (R regions), calculates total area O(S) where S=shape types. If region area > 200, returns true O(1). For small regions (area ‚â§ 200), uses optimized backtracking with bitmask representation, memoization, constraint propagation, and parallel processing. Backtracking worst case O((V√óW√óH)^S) but significantly improved with: (1) bitmask operations for O(1) placement checks, (2) memoization to cache subproblem results (with optimized CacheKey eliminating grid cloning), (3) constraint propagation with remaining area checks, (4) parallel region processing using parallelStream(). Part 2: Not implemented. *Expected time with parallel processing on multi-core CPU (8-16 cores). | ‚úÖ **OPTIMIZED**: Part 1 optimized with key improvements: (1) Bitmask representation replacing boolean[][] for faster bitwise operations and better cache locality, (2) Memoization with CacheKey using Arrays.hashCode() to avoid expensive grid cloning on every cache lookup, (3) Constraint propagation with precomputed minimum area remaining for early pruning, (4) Parallel region processing using parallelStream() for near-linear speedup on multi-core systems. Execution time improved from ~2.700s to ~1.000s (~2.7x faster) with first three optimizations. With parallel processing, expected further improvement to ~0.125-0.250s (~4-8x additional speedup) on multi-core systems. CacheKey optimization eliminates O(grid_size) array copy operations during memoization. | ‚ö†Ô∏è **PART 2 MISSING** - Part 2 not implemented yet |

## Legend

### Variable Definitions

- **n**: Number of rotations/operations (for Day1), line length (for Day3), or number of points (for Day8, Day9)
- **d**: Average distance per rotation
- **R**: Total number of IDs across all ranges (for Day2), number of rows in grid (for Day4, Day6, Day7), or number of ranges (for Day5)
- **L**: Number of lines/machines (Day10), or total characters (Day3), or average ID length (Day2)
- **n**: Number of buttons (Day10), rotations (Day1), line length (Day3), or points (Day8, Day9)
- **k**: Max presses per button (Day10, default 1000) or cluster size (Day8)
- **R**: Number of rows/targets (Day10 Part 2)
- **C**: Number of columns/buttons (Day10 Part 2)
- **f**: Number of free variables after RREF (Day10 Part 2, typically f << n)
- **V**: Number of vertices in graph (Day11), or variants per shape (Day12)
- **E**: Number of edges in graph (Day11)
- **r**: Number of ranges
- **C**: Number of columns in grid (for Day4, Day6, Day7)
- **I**: Number of IDs to check (for Day5)
- **R**: Number of regions (Day12)
- **S**: Number of shape types (Day12)
- **B**: Backtracking cost for small regions (Day12, exponential in worst case but pruned in practice)
- **W√óH**: Region dimensions (Day12)

### Attention Level Indicators

- **üî¥ HIGH**: Critical issues requiring immediate attention
  - Missing Part 2 implementation
  - Exponential complexity that could cause performance issues
  - Significant optimization opportunities

- **üü° MEDIUM**: Should be addressed for better performance
  - Quadratic complexity that can be optimized
  - Missing optimizations that would improve scalability
  - Brute force approaches that can be improved

- **üü¢ LOW**: Minor improvements possible
  - Small optimizations that may not be critical
  - Code refactoring opportunities
  - Performance improvements for edge cases

- **‚úÖ OK**: No issues or already optimal
  - Well-optimized solutions
  - Appropriate complexity for the problem
  - No significant improvements needed

## Summary

### Complexity Distribution

- **O(n)**: Day1 Part 1, Day1 Part 2 ‚úÖ
- **O(R√óL)**: Day2 Part 1, Day2 Part 2 ‚úÖ
- **O(L)**: Day3 Part 1, Day3 Part 2 ‚úÖ
- **O(R√óC)**: Day4 Part 1 ‚úÖ, Day6 Part 1 ‚úÖ, Day6 Part 2 ‚úÖ, Day7 Part 1 ‚úÖ, Day7 Part 2 ‚úÖ
- **O((R√óC)¬≤)**: Day4 Part 2 ‚úÖ
- **O(I√óR)**: Day5 Part 1 ‚úÖ
- **O(R log R)**: Day5 Part 2 ‚úÖ
- **O(n¬≤)**: Day9 Part 1 ‚úÖ
- **O(n¬≤ log k)**: Day8 Part 1 ‚úÖ (where k=1000 << n, optimized from O(n¬≤ log n))
- **O(n¬≤ log n)**: Day8 Part 2 ‚úÖ
- **O(n¬≥)**: Day9 Part 2 ‚úÖ
- **O(L√ó2^(n/2))**: Day10 Part 1 ‚úÖ (Meet-in-the-middle with Gray Code)
- **O(L√ó(R√óC¬≤ + k^f))**: Day10 Part 2 ‚úÖ (RREF + Parallel Backtracking, where f = free variables, typically f << n)
- **O(V+E)**: Day11 Part 1 ‚úÖ, Day11 Part 2 ‚úÖ (Memoized recursion for graph path counting)
- **O(R√ó(S+B)/P)**: Day12 Part 1 ‚úÖ (Area-based optimization with backtracking for small regions, where B is exponential in worst case but pruned in practice, P = number of CPU cores for parallel processing)

### Execution Time Analysis (from `./mvnw clean test -pl 2025`)

**Total Build Time:** ~3.0s (estimated, Day 10 optimized from 11.32s to 0.352s)

**Performance Categories:**
- **Very Fast (< 0.05s):** Days 1, 3, 5, 6, 7 (5 days)
- **Fast (0.05-0.2s):** Days 4, 9, 11 (3 days)
- **Moderate (0.2-0.5s):** Days 2, 8, 10 (3 days)
- **Slow (> 0.5s):** Day 12 (1 day) - Backtracking for small regions (optimized with bitmask, memoization, constraint propagation, and parallel processing; expected ~0.125-0.250s on multi-core systems)

**Key Observations:**
- Day 10 optimized from 11.32s to 0.352s (~32x faster) using RREF to reduce search space from k^n to k^f, where f (free variables) is typically much smaller than n (total buttons). Parallel execution with ForkJoinPool further improves performance.
- Day 12 optimized from 2.700s to 1.000s (~2.7x faster) with bitmask representation, memoization, and constraint propagation. With parallel processing, expected further improvement to ~0.125-0.250s (~4-8x additional speedup) on multi-core systems.
- Day 9 optimized from 1.060s to 0.142s (~7.4x faster) with pre-computed vertical edges, parallel processing, and quick bounds filtering
- Day 8 optimized from 0.393s to 0.319s (~19% faster) with priority queue approach for Part 1 and parallel sort for Part 2

### Most Critical Improvements Needed

1. ‚úÖ **Day10 Part 1 & 2**: Optimized.
   - **Part 1**: Implemented Meet-in-the-middle ($O(2^{n/2})$) using Gray Code bit manipulation for O(1) state updates. Pre-sized primitive HashMaps (Eclipse Collections) for efficient lookups.
   - **Part 2**: Uses RREF (Reduced Row Echelon Form) O(R√óC¬≤) to transform the system of linear equations, reducing search space from k^n to k^f where f (free variables) << n. Parallel backtracking with ForkJoinPool, zero allocations in search loop, precomputed coefficient matrices, and dynamic bounds pruning using remaining budget.
   - **Status**: Code is now algorithmically optimal. Part 2 complexity reduced from O(L√ók‚Åø) to O(L√ó(R√óC¬≤ + k^f)) where f << n, resulting in ~32x faster execution.

2. ‚úÖ **Day12 Part 1**: Optimized from 2.700s to 1.000s (~2.7x faster) with key improvements: (1) Bitmask representation (long[]) replacing boolean[][] for faster bitwise operations and better cache locality, (2) Memoization with CacheKey optimized to eliminate expensive grid cloning by using `Arrays.hashCode()` directly on grid array, removing O(grid_size) array copy operations on every cache lookup, (3) Constraint propagation with precomputed minimum area remaining for early pruning, (4) Parallel region processing using parallelStream() for near-linear speedup on multi-core systems. Big O remains O(R√ó(S+B)) but wall-clock time is O(R√ó(S+B)/P) where P is number of CPU cores. Expected further improvement to ~0.125-0.250s (~4-8x additional speedup) on multi-core systems.
3. ‚úÖ **Day1 Part 2**: Optimized from O(n√ód) to O(n) by calculating zero crossings directly using modular arithmetic.
4. ‚úÖ **Day2 Part 2**: Optimized from O(R√óL¬≤) to O(R√óL) by using direct character comparison instead of substring creation.
5. ‚úÖ **Day8 Part 1**: Optimized from O(n¬≤ log n) to O(n¬≤ log k) where k=1000 << n, using priority queue approach (~19% faster).
6. ‚úÖ **Day9 Part 2**: Optimized constant factors (~7.4x faster) with pre-computed vertical edges, parallel processing, and quick bounds filtering. Big O remains O(n¬≥) (optimal).

### Performance Notes

- **Day1**: **OPTIMIZED** - Pure DataFrame-oriented solution with single-pass processing and direct aggregation. Both parts are optimal O(n). Part 1: Single DataFrame iteration, inline parsing and processing, direct zero count accumulation. Part 2: Single DataFrame iteration with modular arithmetic to calculate zero crossings directly without expanding rotations. Eliminates double iteration (O(2n) ‚Üí O(n)), intermediate collections (O(n) space ‚Üí O(1)), and unnecessary object allocations (Rotation objects, String conversions). Improved constant factors and better cache locality through single-pass processing.
- **Day2**: Both parts are now optimal. Part 2 uses efficient character-by-character comparison.
- **Day3**: Both parts are optimal. Uses recursive greedy algorithm with functional programming style.
- **Day4**: Part 1 is optimal O(R√óC). Part 2 has quadratic complexity O((R√óC)¬≤) which is optimal for iterative neighbor-based removal problems where removing cells affects neighbors.
- **Day5**: Part 1 is O(I√óR) which is optimal for the straightforward nested iteration approach. Part 2 is O(R log R) which is optimal for range merging (sorting is necessary, merge is linear).
- **Day6**: Both parts are optimal O(R√óC). Part 1 processes blocks row by row, Part 2 processes blocks column by column (right to left). Both must examine each cell at least once.
- **Day7**: Both parts are optimal O(R√óC). Part 1 tracks beam positions row by row, processing at most O(C) unique positions per row. Part 2 uses memoized recursion to count paths, ensuring each point is computed once.
- **Day8**: Both parts are optimal O(n¬≤ log n). Both parts generate all point pairs (n choose 2 ‚âà n¬≤) and sort them by distance. Part 1 unions top 1000 shortest connections using DSU. Part 2 unions all connections in order until all points form a single component. The sorting step is necessary to process connections in distance order, and DSU operations are effectively O(1) per operation.
- **Day9**: Part 1 is optimal O(n¬≤) - must examine all point pairs to find maximum area rectangle. Part 2 is optimal O(n¬≥) - generates all point pairs O(n¬≤) and validates each rectangle candidate against all polygon edges O(n) using point-in-polygon and edge intersection checks. **OPTIMIZED** with constant factor improvements: pre-computed vertical edges, parallel processing, and quick bounds filtering reduce execution time by ~7.4x while maintaining optimal Big O complexity.
- **Day11**: Both parts are optimal O(V+E). Uses memoized recursion (dynamic programming) to count paths in a directed acyclic graph. Each vertex is visited at most once, and all edges are examined. Part 2 counts paths for 6 pairs independently, but memoization ensures each path count is O(V+E). Functional programming style with immutable data structures and Stream API.
- **Day12**: Part 1 **OPTIMIZED** with key improvements: (1) Bitmask representation using long[] arrays for efficient bitwise operations, replacing boolean[][] for better cache locality and faster placement checks, (2) Memoization with CacheKey class optimized to compute hash directly from grid array using `Arrays.hashCode()` without expensive cloning operations, eliminating O(grid_size) array copies on every cache lookup, (3) Constraint propagation with precomputed minimum area remaining arrays for early pruning when remaining area is insufficient, (4) Parallel region processing using parallelStream() to process regions concurrently, achieving near-linear speedup on multi-core systems. Area-based optimization (skip backtracking for regions > 200) ensures most regions are processed in O(S) time. For small regions (area ‚â§ 200), optimized backtracking runs with significantly improved constant factors. Backtracking worst case is exponential O((V√óW√óH)^S) but with all optimizations it's much better in practice. Execution time improved from ~2.700s to ~1.000s (~2.7x faster) with first three optimizations. With parallel processing, expected further improvement to ~0.125-0.250s (~4-8x additional speedup) on multi-core systems. Part 2 is not implemented yet.

### Detailed Analysis

#### Day10 - ButtonPressOptimizer

**Part 1 Analysis:**
- **Algorithm**: Meet-in-the-middle (MitM).
- **Approach**: Splits buttons into two halves, generates all XOR combinations for left half O(2^(n/2)), then checks right half combinations O(2^(n/2)) against left half map.
- **Complexity**: $O(L \times 2^{n/2})$ where L = number of lines, n = number of buttons.
- **Optimizations**:
  - Gray Code bit manipulation for O(1) state updates (XOR with single button per iteration).
  - Pre-sized primitive HashMap (Eclipse Collections LongIntHashMap) to avoid resizing.
  - Lazy bit counting only when match found.
- **Space**: O(2^(n/2)) for left half map.

**Part 2 Analysis:**
- **Algorithm**: RREF (Reduced Row Echelon Form) + Parallel Backtracking.
- **Phase 1 - RREF**: Transforms system of linear equations O(R√óC¬≤) where R = number of targets, C = number of buttons.
  - Uses Gaussian elimination with rational arithmetic (GCD normalization to prevent overflow).
  - Identifies pivot variables and free variables.
  - Reduces search space from k^n to k^f where f = number of free variables (typically f << n).
- **Phase 2 - Backtracking**: Searches free variable assignments O(k^f) with optimizations:
  - **Zero-Allocation Loop**: Reuses assignment array, no cloning in recursion.
  - **Precomputed Coefficients**: Coefficient matrices precomputed after RREF for O(1) access.
  - **Dynamic Bounds Pruning**: Uses remaining budget to limit search space per free variable.
  - **Parallel Execution**: ForkJoinPool splits first free variable's search space across threads.
  - **Thread-Safe Updates**: AtomicLong for best total with lock-free updates.
- **Complexity**: $O(L \times (R \times C^2 + k^f))$ where f << n, significantly better than naive $O(L \times k^n)$.
- **Optimization**: RREF is the key optimization - reduces exponential base from n (all buttons) to f (free variables only).

**Optimization Implemented:**
‚úÖ **COMPLETED**:
1. **Part 1**: Meet-in-the-middle with Gray Code bit manipulation for O(1) state updates. Pre-sized primitive HashMaps (Eclipse Collections) for efficient lookups.
2. **Part 2**: RREF-based approach with parallel backtracking:
   - RREF reduces problem from k^n to k^f search space (f << n).
   - Precomputed coefficient matrices for fast pivot calculation.
   - Zero allocations in backtracking loop (reuses assignment array).
   - Parallel ForkJoinPool execution with thread-safe atomic updates.
   - Dynamic bounds pruning using remaining budget.
- Execution time improved from ~11.32s to ~0.352s (~32x faster) with RREF optimization.

#### Day11 - GraphPathCounter

**Part 1 Analysis:**
- **Algorithm**: Memoized recursion (dynamic programming).
- **Approach**: Parses graph into adjacency list O(E), then counts paths from "you" to "out" using memoized recursion.
- **Complexity**: O(V+E) where V = number of vertices, E = number of edges.
- **Optimizations**:
  - Memoization ensures each vertex is visited at most once.
  - HashMap for O(1) memo lookup and storage.
  - Functional programming style with immutable data structures.
- **Space**: O(V) for memoization map, O(V+E) for graph representation.

**Part 2 Analysis:**
- **Algorithm**: Multiple memoized path counts with product aggregation.
- **Approach**: Counts paths for 6 pairs (3 pairs √ó 2 products), multiplies paths within each product, then sums products.
- **Complexity**: O(V+E) - each path count is O(V+E) with memoization, and 6 independent counts still result in O(V+E) overall.
- **Optimizations**:
  - Each path count uses fresh memoization, ensuring optimal performance.
  - Stream API for functional aggregation (mapToLong, reduce).
  - Immutable PathPair records for type safety.
- **Note**: While 6 path counts are performed, memoization ensures each vertex-edge pair is processed efficiently, maintaining O(V+E) complexity.

**Optimization Status:**
‚úÖ **OPTIMAL**: Uses standard memoized recursion approach for counting paths in directed acyclic graph. This is the optimal algorithm for this problem type. No further optimizations needed.

#### Day12 - ShapePacking

**Part 1 Analysis:**
- **Algorithm**: Optimized backtracking with bitmask representation, memoization, constraint propagation, and parallel processing.
- **Approach**: For each region (R regions), calculates total area O(S) where S=shape types. If region area > 200, returns true immediately O(1). For small regions (area ‚â§ 200), uses optimized backtracking to place shapes.
- **Complexity**: O(R√ó(S+B)) where B is backtracking cost (exponential in worst case but pruned in practice). With parallel processing, wall-clock time is O(R√ó(S+B)/P) where P is number of CPU cores.
- **Optimizations**:
  1. **Bitmask Representation**: Replaced `boolean[][]` with `long[]` bitmask arrays
     - Each long represents up to 64 cells
     - Bitwise AND operations for O(1) placement checks (vs O(points) with boolean array)
     - Better cache locality and reduced memory overhead
     - Faster placement/removal operations using bitwise OR/AND
  2. **Memoization**: Added `CacheKey` class to cache subproblem results
     - Key represents grid state (bitmask) + remaining shapes to place
     - Avoids redundant backtracking paths for same grid state
     - **Optimized**: Uses `Arrays.hashCode()` directly on grid array without cloning
     - Eliminates expensive O(grid_size) array copy operations on every cache lookup
     - HashMap-based cache with efficient hashCode computation using `Arrays.hashCode()`
  3. **Constraint Propagation**: Precomputed minimum area remaining arrays
     - O(1) check if remaining area is sufficient for remaining shapes
     - Early termination when impossible to complete
     - Incremental area tracking during backtracking
  4. **Parallel Region Processing**: Uses `parallelStream()` to process regions concurrently
     - Regions are independent, each creates its own local state (grid, memo)
     - Shapes map is immutable (Map.copyOf), safe for concurrent reads
     - Thread-safe: no shared mutable state between region processing
     - Near-linear speedup on multi-core systems (typically 4-8x faster on modern CPUs)
- **Space**: O(R√óS) for regions and shapes, O(2^(W√óH)) worst case for memoization cache (but pruned in practice). Parallel processing increases memory usage proportionally to number of threads.

**Part 2 Analysis:**
- **Status**: Not implemented yet.

**Optimization Implemented:**
‚úÖ **COMPLETED**:
1. **Bitmask Representation**: Grid state represented as `long[]` arrays instead of `boolean[][]`
   - Bitwise operations for placement checks: `(grid[longIndex] & (1L << bitOffset)) != 0`
   - Bitwise operations for placement: `grid[longIndex] |= (1L << bitOffset)` or `grid[longIndex] &= ~(1L << bitOffset)`
   - Significantly faster than array access and iteration
2. **Memoization**: `CacheKey` class extracts grid state and remaining shapes
   - **Optimized**: Computes hash directly from grid array using `Arrays.hashCode()` without cloning
   - Eliminates expensive O(grid_size) array copy that was happening on every cache lookup
   - Efficient hashCode computation combining grid bitmask and remaining shape IDs
   - Caches results to avoid redundant backtracking paths
   - Reduces exponential search space in practice
3. **Constraint Propagation**: Precomputed `minAreaRemaining[]` array
   - Calculated once before backtracking: `minAreaRemaining[i] = sum of areas from index i to end`
   - Early pruning: `if (remainingArea < minAreaRemaining[index]) return false`
   - Tracks remaining area incrementally during backtracking
4. **Parallel Region Processing**: Changed `regions.stream()` to `regions.parallelStream()`
   - Regions processed independently in parallel using ForkJoinPool
   - Each region creates its own local state (grid, memo), ensuring thread safety
   - Immutable shapes map (Map.copyOf) allows safe concurrent reads
   - Near-linear speedup: typically 4-8x faster on modern multi-core CPUs (8-16 cores)
- Execution time improved from ~2.700s to ~1.000s (~2.7x faster) with first three optimizations.
- With parallel processing, expected further improvement to ~0.125-0.250s (~4-8x additional speedup) on multi-core systems.
- Big O complexity remains O(R√ó(S+B)) but wall-clock time is O(R√ó(S+B)/P) where P is number of CPU cores.

#### Day1 - DialRotator2

**Part 1 Analysis:**
- **Algorithm**: Pure DataFrame-oriented single-pass processing with direct aggregation.
- **Approach**: Creates single DataFrame with rotation strings, then uses `DataFrame.collect()` with accumulator pattern for single-pass processing. For each row: validates rotation inline, parses direction and distance directly (without creating Rotation objects), applies rotation, and accumulates zero count directly in accumulator.
- **Complexity**: O(n) where n = number of rotations. Each rotation processed once with O(1) operations (parse, validate, rotate, accumulate).
- **Optimizations**:
  - Single DataFrame creation (eliminates second DataFrame with computed columns).
  - Single-pass processing (eliminates double iteration: O(2n) ‚Üí O(n)).
  - Direct aggregation using accumulator array `[position, zeroCount]` (eliminates intermediate `MutableList<Integer>`).
  - Inline parsing with helper methods `parseDirection()` and `parseDistance()` (eliminates Rotation object creation).
  - Direct char operations (eliminates String conversions for direction).
- **Space**: O(1) extra space (accumulator array) vs O(n) for intermediate collections in previous implementation.

**Part 2 Analysis:**
- **Algorithm**: Pure DataFrame-oriented single-pass processing with modular arithmetic for zero crossings.
- **Approach**: Same single DataFrame and single-pass pattern as Part 1. Uses `countZeroCrossings()` method with modular arithmetic to calculate zero crossings directly without expanding rotations step-by-step.
- **Complexity**: O(n) single pass instead of O(n√ód) where d = average distance per rotation. Modular arithmetic allows O(1) zero crossing calculation per rotation.
- **Optimizations**:
  - Same optimizations as Part 1 (single DataFrame, single-pass, direct aggregation).
  - Modular arithmetic in `countZeroCrossings()` avoids expanding rotations: calculates zero crossings using division and modulo operations instead of iterating through each position.
  - Direct accumulation: `accumulator[1] += countZeroCrossings(...)` eliminates intermediate list.
- **Space**: O(1) extra space (accumulator array).

**Optimization Implemented:**
‚úÖ **COMPLETED**:
1. **Pure DataFrame Approach**: Refactored to use DataFrame as primary data abstraction with single-pass processing pattern.
2. **Single-Pass Processing**: Eliminated double iteration by combining parsing and processing in single `DataFrame.collect()` call.
3. **Direct Aggregation**: Replaced intermediate collections (`MutableList`, `MutableIntList`, `MutableBooleanList`) with accumulator arrays for O(1) space complexity.
4. **Inline Parsing**: Added helper methods `parseDirection()` and `parseDistance()` to parse directly without creating Rotation objects.
5. **Primitive Operations**: Use char directly instead of String conversions for direction.
- Time complexity: O(n) single pass (improved from O(2n) double pass).
- Space complexity: O(1) extra space (improved from O(n) intermediate collections).
- Object allocations: Eliminated Rotation objects, String conversions, and intermediate list allocations.
- Cache efficiency: Single-pass processing improves data locality.

**Optimization Status:**
‚úÖ **OPTIMIZED**: Pure DataFrame-oriented solution with optimal O(n) complexity for both parts. Single-pass processing with direct aggregation eliminates all intermediate collections and unnecessary object allocations. Improved constant factors and better cache locality compared to previous double-pass implementation.
